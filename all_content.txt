=== Dockerfile.go ===
FROM golang:1.25-alpine AS builder

WORKDIR /app
COPY . .
RUN go mod download
RUN go build -o bin/api-gateway cmd/api-gateway/main.go

FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/bin/api-gateway .
COPY .env .
COPY frontend ./frontend 
CMD ["./api-gateway"]
=== Dockerfile.interview ===
FROM python:3.11-slim

WORKDIR /app

COPY cmd/interview-service/requirements.txt .
RUN pip install -r requirements.txt

COPY cmd/interview-service/main.py .

EXPOSE 8765

CMD ["python", "main.py"]
=== Dockerfile.py ===
FROM python:3.11-slim

WORKDIR /app

# Установка системных зависимостей
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Копируем requirements и устанавливаем зависимости
COPY cmd/scoring-service/requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt
RUN pip3 install grpcio grpcio-tools

# Устанавливаем spacy и модель для русского языка
RUN pip3 install spacy
RUN python3 -m spacy download ru_core_news_sm

# Копируем proto файлы
COPY proto /app/proto

# Генерируем Python код из proto
RUN python3 -m grpc_tools.protoc -I /app/proto --python_out=/app --grpc_python_out=/app /app/proto/nlp.proto

# Копируем исходный код сервиса
COPY cmd/scoring-service/main.py /app/

CMD ["python3", "main.py"]
=== Dockerfile.resume ===
FROM golang:1.25-alpine AS builder

WORKDIR /app
COPY . .
RUN go mod download
RUN go build -o bin/resume-service cmd/resume-service/main.go

FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/bin/resume-service .
COPY .env .
CMD ["./resume-service"]
=== README.md ===
## Архитектура
- API Gateway (Gin): Обработка HTTP-запросов.
- Resume Service: Парсинг резюме (Go + Python via gRPC).
- Interview Service: Голосовые интервью (Go + SpeechKit).
- Scoring Service: Оценка (Python NLP).
- Report Service: Отчеты (Go).
- БД: PostgreSQL.
- Кэш: Redis.
- Очереди: Kafka.

## .env 
- DB_URL=postgres://postgres:password@postgres:5432/hrdb?sslmode=disable
- GRPC_PORT=:50051
- HTTP_PORT=:8080
- REDIS_ADDR=redis:6379
- KAFKA_BROKERS=kafka:9092
=== cmd/api-gateway/main.go ===
package main

import (
	"log"

	"github.com/gin-gonic/gin"
	"github.com/moverq1337/VTBHack/internal/config"
	"github.com/moverq1337/VTBHack/internal/db"
	"github.com/moverq1337/VTBHack/internal/handlers"
	"github.com/moverq1337/VTBHack/scripts"
)

func main() {
	cfg, err := config.Load()
	if err != nil {
		log.Fatal(err)
	}

	scripts.Migrate()

	dbConn, err := db.Connect(cfg.DBURL)
	if err != nil {
		log.Fatal(err)
	}

	r := gin.Default()

	// Настройка CORS для фронтенда
	r.Use(func(c *gin.Context) {
		c.Writer.Header().Set("Access-Control-Allow-Origin", "*")
		c.Writer.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
		c.Writer.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")

		if c.Request.Method == "OPTIONS" {
			c.AbortWithStatus(204)
			return
		}

		c.Next()
	})

	// Настройка маршрутов API Gateway
	handlers.SetupRoutes(r, dbConn)

	log.Printf("API Gateway запущен на порту %s", cfg.HTTPPort)
	if err := r.Run(cfg.HTTPPort); err != nil {
		log.Fatal(err)
	}
}

=== cmd/interview-service/main.py ===
import asyncio
import websockets
import json
import base64
import logging
from typing import Dict
import uuid
import io
import wave
import tempfile
import os
from gtts import gTTS
import edge_tts
import aiohttp
from datetime import datetime

# Настройка логирования
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('interview_service.log')
    ]
)
logger = logging.getLogger(__name__)

class InterviewManager:
    def __init__(self):
        self.sessions: Dict[str, dict] = {}
        self.questions = [
            "Расскажите о вашем опыте работы с Docker и контейнеризацией",
            "Как вы организуете процесс CI/CD в своих проектах?",
            "Какие методы мониторинга и логирования вы используете?",
            "Расскажите о вашем опыте работы с облачными платформами"
        ]

    def create_session(self, candidate_id: str, vacancy_id: str) -> str:
        session_id = str(uuid.uuid4())
        self.sessions[session_id] = {
            'candidate_id': candidate_id,
            'vacancy_id': vacancy_id,
            'current_question': 0,
            'answers': [],
            'score': 0,
            'start_time': datetime.now().isoformat()
        }
        logger.info(f"Создана сессия интервью: {session_id}")
        return session_id

    def get_next_question(self, session_id: str) -> str:
        session = self.sessions.get(session_id)
        if not session:
            logger.warning(f"Сессия не найдена: {session_id}")
            return None

        if session['current_question'] < len(self.questions):
            question = self.questions[session['current_question']]
            logger.info(f"Вопрос {session['current_question'] + 1}: {question}")
            return question
        logger.info("Все вопросы заданы")
        return None

    def save_answer(self, session_id: str, answer: str, score: float):
        session = self.sessions.get(session_id)
        if not session:
            logger.error(f"Сессия не найдена при сохранении ответа: {session_id}")
            return False

        question = self.questions[session['current_question']]
        session['answers'].append({
            'question': question,
            'answer': answer,
            'score': score,
            'timestamp': datetime.now().isoformat()
        })
        session['score'] += score
        session['current_question'] += 1

        logger.info(f"Сохранен ответ для сессии {session_id}: score={score}, answer_length={len(answer)}")
        return True

    def get_results(self, session_id: str) -> dict:
        session = self.sessions.get(session_id)
        if not session:
            logger.warning(f"Сессия не найдена при получении результатов: {session_id}")
            return None

        session['end_time'] = datetime.now().isoformat()
        session['duration'] = (datetime.fromisoformat(session['end_time']) -
                              datetime.fromisoformat(session['start_time'])).total_seconds()

        logger.info(f"Интервью завершено: {session_id}, длительность: {session['duration']} сек")
        return session

interview_manager = InterviewManager()

async def text_to_speech(text: str, lang: str = 'ru') -> bytes:
    """Преобразование текста в речь"""
    try:
        logger.info(f"Синтез речи: '{text}'")

        # Используем gTTS (Google Text-to-Speech)
        tts = gTTS(text=text, lang=lang, slow=False)

        # Сохраняем во временный файл
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
            tts.save(tmp_file.name)
            with open(tmp_file.name, 'rb') as f:
                audio_data = f.read()

        os.unlink(tmp_file.name)
        logger.info(f"Аудио сгенерировано, размер: {len(audio_data)} байт")
        return audio_data

    except Exception as e:
        logger.error(f"Ошибка синтеза речи: {e}")
        # Возвращаем пустые данные в случае ошибки
        return b''

async def speech_to_text(audio_data: bytes) -> str:
    """Преобразование речи в текст (заглушка для MVP)"""
    try:
        logger.info(f"Распознавание речи, размер аудио: {len(audio_data)} байт")

        # Здесь должна быть интеграция с настоящим Speech-to-Text сервисом
        # Например: Yandex SpeechKit, Google Speech-to-Text, etc.

        # Заглушка для демонстрации
        await asyncio.sleep(1)  # Имитация обработки

        # Автоматически генерируем ответ на основе вопроса
        current_session = None
        for session_id, session in interview_manager.sessions.items():
            if session['current_question'] > 0:
                current_session = session
                break

        if current_session:
            current_question_idx = current_session['current_question']
            question = interview_manager.questions[current_question_idx]

            if "Docker" in question:
                transcribed_text = "Я работал с Docker более 3 лет, использовал его для контейнеризации микросервисов. Настраивал Docker Compose для локальной разработки и Docker Swarm для продакшена."
                score = 0.85
            elif "CI/CD" in question:
                transcribed_text = "Настраивал Jenkins и GitLab CI для автоматической сборки и деплоя. Использовал пайплайны для тестирования, сборки и развертывания приложений."
                score = 0.78
            elif "мониторинг" in question:
                transcribed_text = "Использовал Prometheus для сбора метрик, Grafana для визуализации и ELK стек для логирования. Настраивал алерты на критические ошибки."
                score = 0.82
            elif "облачны" in question:
                transcribed_text = "Работал с AWS и Yandex Cloud. Настраивал VPC, EC2 инстансы, S3 хранилища и управлял Kubernetes кластерами."
                score = 0.80
            else:
                transcribed_text = "Кандидат продемонстрировал хорошие технические знания и опыт работы в данной области."
                score = 0.75
        else:
            transcribed_text = "Спасибо за ваш ответ. Переходим к следующему вопросу."
            score = 0.7

        logger.info(f"Распознанный текст: '{transcribed_text}', оценка: {score}")
        return transcribed_text, score

    except Exception as e:
        logger.error(f"Ошибка распознавания речи: {e}")
        return "Извините, не удалось распознать речь.", 0.3

async def handle_interview(websocket):
    client_ip = websocket.remote_address[0]
    logger.info(f"Новое подключение от {client_ip}")

    try:
        async for message in websocket:
            data = json.loads(message)
            logger.info(f"Получено сообщение типа: {data['type']}")

            if data['type'] == 'start_interview':
                # Начинаем новое интервью
                session_id = interview_manager.create_session(
                    data['candidate_id'],
                    data['vacancy_id']
                )
                first_question = interview_manager.get_next_question(session_id)

                # Генерируем аудио вопроса
                question_audio = await text_to_speech(first_question)
                audio_base64 = base64.b64encode(question_audio).decode('utf-8')

                await websocket.send(json.dumps({
                    'type': 'question',
                    'session_id': session_id,
                    'question': first_question,
                    'question_audio': audio_base64,
                    'question_number': 1,
                    'total_questions': len(interview_manager.questions)
                }))
                logger.info(f"Отправлен вопрос 1 для сессии {session_id}")

            elif data['type'] == 'audio_response':
                # Обрабатываем аудио ответ
                session_id = data['session_id']
                logger.info(f"Обработка аудио ответа для сессии {session_id}")

                try:
                    audio_data = base64.b64decode(data['audio'])
                    logger.info(f"Получено аудио: {len(audio_data)} байт")

                    # Распознаем речь
                    transcribed_text, score = await speech_to_text(audio_data)

                    # Сохраняем ответ
                    interview_manager.save_answer(session_id, transcribed_text, score)

                    # Получаем следующий вопрос
                    next_question = interview_manager.get_next_question(session_id)

                    if next_question:
                        # Генерируем аудио следующего вопроса
                        question_audio = await text_to_speech(next_question)
                        audio_base64 = base64.b64encode(question_audio).decode('utf-8')

                        await websocket.send(json.dumps({
                            'type': 'question',
                            'session_id': session_id,
                            'question': next_question,
                            'question_audio': audio_base64,
                            'question_number': interview_manager.sessions[session_id]['current_question'] + 1,
                            'total_questions': len(interview_manager.questions)
                        }))
                        logger.info(f"Отправлен вопрос {interview_manager.sessions[session_id]['current_question'] + 1}")
                    else:
                        # Интервью завершено
                        results = interview_manager.get_results(session_id)
                        await websocket.send(json.dumps({
                            'type': 'interview_completed',
                            'session_id': session_id,
                            'score': results['score'],
                            'answers': results['answers'],
                            'total_score': results['score'] * 25,  # Конвертируем в 100-балльную систему
                            'duration': results['duration']
                        }))
                        logger.info(f"Интервью завершено для сессии {session_id}")

                except Exception as e:
                    logger.error(f"Ошибка обработки аудио: {e}")
                    await websocket.send(json.dumps({
                        'type': 'error',
                        'message': 'Ошибка обработки аудио ответа'
                    }))

    except websockets.exceptions.ConnectionClosed as e:
        logger.info(f"Соединение закрыто: {e}")
    except Exception as e:
        logger.error(f"Ошибка в обработчике интервью: {e}")
        try:
            await websocket.send(json.dumps({
                'type': 'error',
                'message': 'Внутренняя ошибка сервера'
            }))
        except:
            pass

async def health_check():
    """Периодическая проверка здоровья сервиса"""
    while True:
        logger.info(f"Активных сессий: {len(interview_manager.sessions)}")
        await asyncio.sleep(60)

async def main():
    # Запускаем фоновую задачу для проверки здоровья
    asyncio.create_task(health_check())

    # Запускаем WebSocket сервер
    server = await websockets.serve(handle_interview, "0.0.0.0", 8765)
    logger.info("WebSocket сервер запущен на порту 8765")

    try:
        await server.wait_closed()
    except KeyboardInterrupt:
        logger.info("Остановка сервера...")
    except Exception as e:
        logger.error(f"Ошибка сервера: {e}")

if __name__ == "__main__":
    asyncio.run(main())
=== cmd/interview-service/requirements.txt ===
websockets==12.0
gTTS==2.3.2
edge-tts==6.1.3
aiohttp==3.9.1
uuid==1.30
=== cmd/resume-service/main.go ===
package main

import (
	"log"

	"github.com/gin-gonic/gin"
	"github.com/moverq1337/VTBHack/internal/config"
	"github.com/moverq1337/VTBHack/internal/db"
	"github.com/moverq1337/VTBHack/internal/handlers"
)

func main() {
	cfg, err := config.Load()
	if err != nil {
		log.Fatal(err)
	}

	dbConn, err := db.Connect(cfg.DBURL)
	if err != nil {
		log.Fatal(err)
	}

	r := gin.Default()

	// Настройка CORS
	r.Use(func(c *gin.Context) {
		c.Writer.Header().Set("Access-Control-Allow-Origin", "*")
		c.Writer.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
		c.Writer.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")

		if c.Request.Method == "OPTIONS" {
			c.AbortWithStatus(204)
			return
		}

		c.Next()
	})

	// Настройка маршрутов для Resume Service
	handlers.SetupResumeRoutes(r, dbConn)

	log.Printf("Resume Service запущен на порту %s", cfg.HTTPPort)
	if err := r.Run(cfg.HTTPPort); err != nil {
		log.Fatal(err)
	}
}

=== cmd/scoring-service/main.py ===
# scoring-service/main.py
import grpc
from concurrent import futures
import time
import nlp_pb2
import nlp_pb2_grpc
import json
import spacy
import re
import logging
from datetime import datetime
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from collections import defaultdict

# Настройка логирования
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('scoring_service.log')
    ]
)
logger = logging.getLogger(__name__)

# Загрузка моделей
logger.info("Загрузка моделей NLP...")
try:
    nlp = spacy.load("ru_core_news_sm")
    sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    logger.info("Модели успешно загружены")
except Exception as e:
    logger.error(f"Ошибка загрузки моделей: {e}")
    raise

class NLPService(nlp_pb2_grpc.NLPServiceServicer):
    def extract_experience(self, text):
        """Извлечение опыта работы из текста резюме"""
        logger.info("Извлечение опыта работы из резюме")

        # Улучшенные паттерны для поиска опыта работы
        experience_patterns = [
            r'Опыт работы.*?(\d+)[^\d]*год',
            r'(\d+)[^\d]*лет.*?опыт',
            r'стаж.*?(\d+)[^\d]*год',
            r'работаю.*?(\d+)[^\d]*год',
            r'experience.*?(\d+)[^\d]*year'
        ]

        max_experience = 0
        for pattern in experience_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                exp = int(match.group(1))
                if exp > max_experience:
                    max_experience = exp

        # Если не нашли цифры, попробуем определить по датам
        if max_experience == 0:
            date_pattern = r'(\d{4})\s*[-—]\s*(\d{4}|настоящее|н\.в\.|сейчас)'
            dates = re.findall(date_pattern, text)
            if dates:
                current_year = datetime.now().year
                total_experience = 0
                for start_year, end_year in dates:
                    try:
                        start = int(start_year)
                        end = current_year if end_year in ['настоящее', 'н.в.', 'сейчас'] else int(end_year)
                        exp = end - start
                        total_experience += exp
                    except:
                        continue

                if total_experience > 0:
                    max_experience = total_experience / len(dates)  # Средний опыт

        logger.info(f"Найден опыт: {max_experience} лет")
        return max_experience

    def extract_skills(self, text):
        """Извлечение навыков из текста резюме"""
        logger.info("Извлечение навыков из резюме")

        # Расширенный список навыков
        skill_categories = {
            'programming': ['python', 'java', 'javascript', 'c#', 'c++', 'php', 'ruby', 'go', 'rust'],
            'web': ['html', 'css', 'react', 'angular', 'vue', 'django', 'flask', 'node.js', 'express'],
            'database': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle'],
            'devops': ['docker', 'kubernetes', 'jenkins', 'git', 'ci/cd', 'ansible', 'terraform'],
            'os': ['linux', 'windows', 'macos', 'ubuntu', 'debian', 'centos'],
            'networking': ['tcp/ip', 'dns', 'dhcp', 'vpn', 'lan', 'wan'],
            'cloud': ['aws', 'azure', 'google cloud', 'gcp', 'digitalocean'],
            'soft': ['лидерство', 'коммуникация', 'аналитика', 'решение проблем', 'тайм-менеджмент']
        }

        found_skills = defaultdict(list)
        text_lower = text.lower()

        for category, skills in skill_categories.items():
            for skill in skills:
                if re.search(r'\b' + re.escape(skill) + r'\b', text_lower):
                    found_skills[category].append(skill)

        logger.info(f"Найдены навыки: {dict(found_skills)}")
        return dict(found_skills)

    def extract_education(self, text):
        """Извлечение образования из текста резюме"""
        logger.info("Извлечение образования из резюме")

        education_patterns = [
            r'высшее образование',
            r'среднее специальное',
            r'неоконченное высшее',
            r'бакалавр',
            r'магистр',
            r'кандидат наук',
            r'доктор наук'
        ]

        education_levels = []
        for pattern in education_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                education_levels.append(pattern)

        # Извлечение учебных заведений
        universities = []
        uni_patterns = [
            r'([А-Я][а-я]+\s*(университет|институт|академия))',
            r'([А-Я][а-я]+\s*государственный\s*(университет|институт))',
            r'(МГУ|СПбГУ|МФТИ|МГТУ|ВШЭ)'
        ]

        for pattern in uni_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                universities.append(match.group(0))

        result = {
            "levels": education_levels,
            "institutions": list(set(universities))  # Убираем дубликаты
        }

        logger.info(f"Найдено образование: {result}")
        return result

    def ParseResume(self, request, context):
        """Парсинг резюме и извлечение структурированных данных"""
        logger.info(f"Начало парсинга резюме, длина текста: {len(request.text)} символов")

        text = request.text

        try:
            # Извлечение опыта работы
            experience = self.extract_experience(text)

            # Извлечение навыков
            skills = self.extract_skills(text)

            # Извлечение образования
            education = self.extract_education(text)

            # Извлечение языков
            languages = ['Русский']  # По умолчанию
            lang_patterns = {
                'Английский': r'английский',
                'Немецкий': r'немецкий',
                'Французский': r'французский',
                'Испанский': r'испанский',
                'Китайский': r'китайский'
            }

            for lang, pattern in lang_patterns.items():
                if re.search(pattern, text, re.IGNORECASE):
                    languages.append(lang)

            parsed_data = {
                "skills": skills,
                "experience": experience,
                "education": education,
                "languages": languages
            }

            logger.info(f"Результаты парсинга: {parsed_data}")
            return nlp_pb2.ParseResponse(parsed_data=json.dumps(parsed_data, ensure_ascii=False))

        except Exception as e:
            logger.error(f"Ошибка при парсинге резюме: {e}")
            # Возвращаем пустые данные в случае ошибки
            return nlp_pb2.ParseResponse(parsed_data=json.dumps({
                "skills": {},
                "experience": 0,
                "education": {"levels": [], "institutions": []},
                "languages": ["Русский"]
            }, ensure_ascii=False))

    def MatchResumeVacancy(self, request, context):
        """Сопоставление резюме с вакансией с улучшенным анализом"""
        logger.info(f"Сопоставление резюме с вакансией, длина текстов: {len(request.resume_text)}/{len(request.vacancy_text)}")

        resume_text = request.resume_text
        vacancy_text = request.vacancy_text

        try:
            # Базовое сравнение на основе эмбеддингов
            resume_embedding = sentence_model.encode([resume_text])
            vacancy_embedding = sentence_model.encode([vacancy_text])
            base_score = cosine_similarity(resume_embedding, vacancy_embedding)[0][0]

            # Дополнительные факторы для улучшения оценки
            additional_score = 0

            # Проверка соответствия навыков
            resume_skills = self.extract_skills(resume_text)
            vacancy_skills = self.extract_skills(vacancy_text)

            # Считаем совпадение навыков
            matched_skills = 0
            total_skills = 0

            for category, skills in vacancy_skills.items():
                for skill in skills:
                    total_skills += 1
                    if any(s in str(resume_skills.values()).lower() for s in skill.lower().split()):
                        matched_skills += 1

            skill_match_ratio = matched_skills / total_skills if total_skills > 0 else 0

            # Проверка соответствия опыта
            resume_exp = self.extract_experience(resume_text)
            vacancy_exp = self.extract_experience(vacancy_text)

            exp_match = 1 if resume_exp >= vacancy_exp else resume_exp / vacancy_exp

            # Комбинированная оценка
            final_score = 0.5 * base_score + 0.3 * skill_match_ratio + 0.2 * exp_match
            final_score = max(0, min(1, final_score))  # Нормализуем от 0 до 1

            logger.info(f"Базовый score: {base_score:.2f}, Совпадение навыков: {skill_match_ratio:.2f}, Совпадение опыта: {exp_match:.2f}")
            logger.info(f"Итоговый score: {final_score:.2f}")

            return nlp_pb2.MatchResponse(score=final_score)

        except Exception as e:
            logger.error(f"Ошибка при сопоставлении: {e}")
            return nlp_pb2.MatchResponse(score=0.0)

def serve():
    logger.info("Запуск gRPC сервера на порту 50051")
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    nlp_pb2_grpc.add_NLPServiceServicer_to_server(NLPService(), server)
    server.add_insecure_port('[::]:50051')
    server.start()
    logger.info("gRPC сервер успешно запущен")

    try:
        server.wait_for_termination()
    except KeyboardInterrupt:
        logger.info("Остановка сервера...")
        server.stop(0)

if __name__ == '__main__':
    serve()
=== cmd/scoring-service/nlp_pb2.py ===
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nlp.proto
# Protobuf Python Version: 5.26.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\tnlp.proto\x12\x02pb\"\x1c\n\x0cParseRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\"$\n\rParseResponse\x12\x13\n\x0bparsed_data\x18\x01 \x01(\t\"9\n\x0cMatchRequest\x12\x13\n\x0bresume_text\x18\x01 \x01(\t\x12\x14\n\x0cvacancy_text\x18\x02 \x01(\t\"\x1e\n\rMatchResponse\x12\r\n\x05score\x18\x01 \x01(\x02\x32{\n\nNLPService\x12\x32\n\x0bParseResume\x12\x10.pb.ParseRequest\x1a\x11.pb.ParseResponse\x12\x39\n\x12MatchResumeVacancy\x12\x10.pb.MatchRequest\x1a\x11.pb.MatchResponseB+Z)github.com/moverq1337/VTBHack/internal/pbb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'nlp_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z)github.com/moverq1337/VTBHack/internal/pb'
  _globals['_PARSEREQUEST']._serialized_start=17
  _globals['_PARSEREQUEST']._serialized_end=45
  _globals['_PARSERESPONSE']._serialized_start=47
  _globals['_PARSERESPONSE']._serialized_end=83
  _globals['_MATCHREQUEST']._serialized_start=85
  _globals['_MATCHREQUEST']._serialized_end=142
  _globals['_MATCHRESPONSE']._serialized_start=144
  _globals['_MATCHRESPONSE']._serialized_end=174
  _globals['_NLPSERVICE']._serialized_start=176
  _globals['_NLPSERVICE']._serialized_end=299
# @@protoc_insertion_point(module_scope)

=== cmd/scoring-service/nlp_pb2_grpc.py ===
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

import nlp_pb2 as nlp__pb2

GRPC_GENERATED_VERSION = '1.64.1'
GRPC_VERSION = grpc.__version__
EXPECTED_ERROR_RELEASE = '1.65.0'
SCHEDULED_RELEASE_DATE = 'June 25, 2024'
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    warnings.warn(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + f' but the generated code in nlp_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
        + f' This warning will become an error in {EXPECTED_ERROR_RELEASE},'
        + f' scheduled for release on {SCHEDULED_RELEASE_DATE}.',
        RuntimeWarning
    )


class NLPServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.ParseResume = channel.unary_unary(
                '/pb.NLPService/ParseResume',
                request_serializer=nlp__pb2.ParseRequest.SerializeToString,
                response_deserializer=nlp__pb2.ParseResponse.FromString,
                _registered_method=True)
        self.MatchResumeVacancy = channel.unary_unary(
                '/pb.NLPService/MatchResumeVacancy',
                request_serializer=nlp__pb2.MatchRequest.SerializeToString,
                response_deserializer=nlp__pb2.MatchResponse.FromString,
                _registered_method=True)


class NLPServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def ParseResume(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def MatchResumeVacancy(self, request, context):
        """Новый метод
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_NLPServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'ParseResume': grpc.unary_unary_rpc_method_handler(
                    servicer.ParseResume,
                    request_deserializer=nlp__pb2.ParseRequest.FromString,
                    response_serializer=nlp__pb2.ParseResponse.SerializeToString,
            ),
            'MatchResumeVacancy': grpc.unary_unary_rpc_method_handler(
                    servicer.MatchResumeVacancy,
                    request_deserializer=nlp__pb2.MatchRequest.FromString,
                    response_serializer=nlp__pb2.MatchResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'pb.NLPService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('pb.NLPService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class NLPService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def ParseResume(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/pb.NLPService/ParseResume',
            nlp__pb2.ParseRequest.SerializeToString,
            nlp__pb2.ParseResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def MatchResumeVacancy(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/pb.NLPService/MatchResumeVacancy',
            nlp__pb2.MatchRequest.SerializeToString,
            nlp__pb2.MatchResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

=== cmd/scoring-service/requirements.txt ===
grpcio==1.64.1
grpcio-tools==1.64.1
spacy==3.7.5
sentence-transformers==3.0.1
scikit-learn==1.5.0
numpy==1.26.4
=== create_test.sh ===
ROOT_DIR="./"

find "$ROOT_DIR" -type d ! -path "*/.*" | while read -r dir; do
    file="$dir/test.test"
    if [ ! -f "$file" ]; then
        touch "$file"
        echo "Создан: $file"
    else
        echo "Уже существует: $file"
    fi
done

=== docker-compose.yml ===
version: '3.8'

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: hrdb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - kafka-net

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - kafka-net

  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_INIT_LIMIT: 3
      ZOOKEEPER_SYNC_LIMIT: 2
    networks:
      - kafka-net

  kafka1:
    image: confluentinc/cp-kafka:7.7.1
    hostname: kafka1
    container_name: kafka1
    depends_on:
      - zookeeper
    ports:
      - "9091:9091"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29091,PLAINTEXT_HOST://localhost:9091
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MESSAGE_MAX_BYTES: 104857600
    networks:
      - kafka-net

  kafka2:
    image: confluentinc/cp-kafka:7.7.1
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MESSAGE_MAX_BYTES: 104857600
    networks:
      - kafka-net

  kafka3:
    image: confluentinc/cp-kafka:7.7.1
    hostname: kafka3
    container_name: kafka3
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MESSAGE_MAX_BYTES: 104857600
    networks:
      - kafka-net

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8888:8080"
    environment:
      AUTH_TYPE: DISABLED
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:29091,kafka2:29092,kafka3:29093
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    networks:
      - kafka-net

  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile.go
    ports:
      - "8080:8080"
    environment:
      - DB_URL=postgres://postgres:password@postgres:5432/hrdb?sslmode=disable
      - REDIS_ADDR=redis:6379
      - KAFKA_BROKERS=kafka1:29091,kafka2:29092,kafka3:29093
      - GRPC_HOST=scoring-service  # ← ДОБАВЬТЕ ЭТУ СТРОКУ
      - GRPC_PORT=50051           # ← ДОБАВЬТЕ ЭТУ СТРОКУ
    depends_on:
      - postgres
      - redis
      - kafka1
      - kafka2
      - kafka3
      - scoring-service           # ← ДОБАВЬТЕ ЭТУ ЗАВИСИМОСТЬ
    networks:
      - kafka-net

  resume-service:
    build:
      context: .
      dockerfile: Dockerfile.resume
    ports:
      - "8081:8081"
    environment:
      - DB_URL=postgres://postgres:password@postgres:5432/hrdb?sslmode=disable
      - GRPC_HOST=scoring-service
      - GRPC_PORT=50051
      - HTTP_PORT=:8081
      - REDIS_ADDR=redis:6379
      - KAFKA_BROKERS=kafka1:29091,kafka2:29092,kafka3:29093
      - YANDEX_DISK_TOKEN=${YANDEX_DISK_TOKEN}
    depends_on:
      - postgres
      - scoring-service
      - redis
      - kafka1
      - kafka2
      - kafka3
    networks:
      - kafka-net


  scoring-service:
    build:
      context: .
      dockerfile: Dockerfile.py
    ports:
      - "50051:50051"
    environment:
      - PYTHONPATH=/app
    networks:
      - kafka-net

  interview-service:
    build:
      context: .
      dockerfile: Dockerfile.interview
    ports:
      - "8765:8765"
    networks:
      - kafka-net

volumes:
  postgres-data:
  redis-data:

networks:
  kafka-net:
    driver: bridge
=== frontend/interview.html ===
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HR Avatar - Голосовое интервью</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .question {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 20px;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin-right: 10px;
            cursor: pointer;
        }
        .progress {
            margin: 20px 0;
        }
        .results {
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .progress-bar {
            width: 100%;
            height: 20px;
            background-color: #f0f0f0;
            border-radius: 10px;
            margin: 10px 0;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            background-color: #4CAF50;
            width: 0%;
            transition: width 0.3s ease;
        }
        .processing {
            display: none;
            margin: 10px 0;
        }
    </style>
</head>
<body>
<h1>HR Avatar - Голосовое интервью</h1>

<div id="setup">
    <h2>Настройка интервью</h2>
    <div>
        <label>ID кандидата: <input type="text" id="candidateId" value="22328f8d-79fa-4a43-85bd-9bf0149da004"></label>
    </div>
    <div>
        <label>ID вакансии: <input type="text" id="vacancyId" value="8b49b6cd-1411-4c41-8176-a26524468eb2"></label>
    </div>
    <button onclick="startInterview()">Начать интервью</button>
</div>

<div id="interview" style="display: none;">
    <div class="progress">
        Вопрос <span id="currentQuestion">1</span> из <span id="totalQuestions">4</span>
    </div>
    <div class="question" id="questionText"></div>

    <div class="controls">
        <button id="recordBtn" onclick="toggleRecording()">Начать запись</button>
        <button id="nextBtn" onclick="nextQuestion()" disabled>Следующий вопрос</button>
    </div>

    <div class="processing" id="processing">
        <div class="progress-bar">
            <div class="progress-fill" id="progressFill"></div>
        </div>
        <p>Обработка ответа... <span id="progressText">0%</span></p>
    </div>

    <div id="status"></div>
</div>

<div id="results" class="results" style="display: none;">
    <h2>Результаты интервью</h2>
    <div id="resultsContent"></div>
</div>

<script>
    let websocket;
    let mediaRecorder;
    let audioChunks = [];
    let sessionId;
    let isRecording = false;
    websocket.onmessage = async function(event) {
        const data = JSON.parse(event.data);
        logger.info(`Получено сообщение типа: ${data.type}`);

        if (data.type === 'question') {
            sessionId = data.session_id;

            // Воспроизводим аудио вопроса
            if (data.question_audio) {
                await playQuestionAudio(data.question_audio);
            }

            document.getElementById('questionText').textContent = data.question;
            document.getElementById('currentQuestion').textContent = data.question_number;
            document.getElementById('totalQuestions').textContent = data.total_questions;
            document.getElementById('nextBtn').disabled = true;
            document.getElementById('recordBtn').disabled = false;
        }
        else if (data.type === 'interview_completed') {
            showResults(data);
        }
        else if (data.type === 'error') {
            document.getElementById('status').textContent = 'Ошибка: ' + data.message;
            document.getElementById('recordBtn').disabled = false;
        }
    };

    async function playQuestionAudio(audioBase64) {
        try {
            const audioBlob = new Blob(
                [Uint8Array.from(atob(audioBase64), c => c.charCodeAt(0))],
                { type: 'audio/mp3' }
            );
            const audioUrl = URL.createObjectURL(audioBlob);

            const audio = new Audio(audioUrl);
            document.getElementById('status').textContent = 'Воспроизведение вопроса...';

            await new Promise((resolve) => {
                audio.onended = resolve;
                audio.play();
            });

            URL.revokeObjectURL(audioUrl);
            document.getElementById('status').textContent = 'Вопрос завершен, готово к записи';

        } catch (error) {
            console.error('Ошибка воспроизведения аудио:', error);
            document.getElementById('status').textContent = 'Готово к записи ответа';
        }
    }

    async function simulateProcessing() {
        const processingElem = document.getElementById('processing');
        const progressFill = document.getElementById('progressFill');
        const progressText = document.getElementById('progressText');

        processingElem.style.display = 'block';

        for (let i = 0; i <= 100; i += 5) {
            progressFill.style.width = i + '%';
            progressText.textContent = i + '%';
            await new Promise(resolve => setTimeout(resolve, 50));
        }

        processingElem.style.display = 'none';
    }

    async function startInterview() {
        const candidateId = document.getElementById('candidateId').value;
        const vacancyId = document.getElementById('vacancyId').value;

        if (!candidateId || !vacancyId) {
            alert('Заполните ID кандидата и вакансии');
            return;
        }

        // Подключаемся к WebSocket серверу
        websocket = new WebSocket('ws://localhost:8765');

        websocket.onopen = function() {
            document.getElementById('setup').style.display = 'none';
            document.getElementById('interview').style.display = 'block';

            // Начинаем интервью
            websocket.send(JSON.stringify({
                type: 'start_interview',
                candidate_id: candidateId,
                vacancy_id: vacancyId
            }));
        };

        websocket.onmessage = function(event) {
            const data = JSON.parse(event.data);

            if (data.type === 'question') {
                sessionId = data.session_id;
                document.getElementById('questionText').textContent = data.question;
                document.getElementById('currentQuestion').textContent = data.question_number;
                document.getElementById('totalQuestions').textContent = data.total_questions;
                document.getElementById('nextBtn').disabled = true;
                document.getElementById('recordBtn').disabled = false;
            }
            else if (data.type === 'interview_completed') {
                showResults(data);
            }
        };

        websocket.onerror = function(error) {
            console.error('WebSocket ошибка:', error);
            alert('Ошибка подключения к серверу интервью');
        };
    }

    async function toggleRecording() {
        if (!isRecording) {
            // Начинаем запись
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        volume: 1.0
                    }
                });
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 16000
                });
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const reader = new FileReader();

                    reader.onload = async function() {
                        // Показываем прогресс бар
                        await simulateProcessing();

                        const base64Audio = reader.result.split(',')[1];

                        // Отправляем аудио на сервер
                        websocket.send(JSON.stringify({
                            type: 'audio_response',
                            session_id: sessionId,
                            audio: base64Audio
                        }));

                        document.getElementById('status').textContent = 'Ответ отправлен';
                    };

                    reader.readAsDataURL(audioBlob);
                };

                mediaRecorder.start();
                isRecording = true;
                document.getElementById('recordBtn').textContent = 'Остановить запись';
                document.getElementById('status').textContent = 'Идет запись...';
            } catch (error) {
                console.error('Ошибка доступа к микрофону:', error);
                alert('Не удалось получить доступ к микрофону');
            }
        } else {
            // Останавливаем запись
            mediaRecorder.stop();
            isRecording = false;
            document.getElementById('recordBtn').textContent = 'Начать запись';
            document.getElementById('recordBtn').disabled = true;
        }
    }

    function nextQuestion() {
        document.getElementById('recordBtn').disabled = false;
        document.getElementById('nextBtn').disabled = true;
        document.getElementById('status').textContent = 'Готово к записи';
    }

    function showResults(data) {
        document.getElementById('interview').style.display = 'none';
        document.getElementById('results').style.display = 'block';

        let resultsHtml = `<p><strong>Общий балл: ${(data.score * 25).toFixed(1)}/100</strong></p>`;

        data.answers.forEach((answer, index) => {
            resultsHtml += `
                    <div>
                        <p><strong>Вопрос ${index + 1}:</strong> ${answer.question}</p>
                        <p><strong>Ответ:</strong> ${answer.answer}</p>
                        <p><strong>Балл:</strong> ${(answer.score * 25).toFixed(1)}/25</p>
                        <hr>
                    </div>
                `;
        });

        document.getElementById('resultsContent').innerHTML = resultsHtml;
    }
</script>
</body>
</html>
=== go.mod ===
module github.com/moverq1337/VTBHack

go 1.25.0

require (
	github.com/gin-gonic/gin v1.10.1
	github.com/google/uuid v1.6.0
	github.com/joho/godotenv v1.5.1
	github.com/sirupsen/logrus v1.9.3
	github.com/unidoc/unioffice v1.39.0
	google.golang.org/grpc v1.75.0
	google.golang.org/protobuf v1.36.6
	gorm.io/driver/postgres v1.6.0
	gorm.io/gorm v1.30.2
)

require (
	github.com/bytedance/sonic v1.11.6 // indirect
	github.com/bytedance/sonic/loader v0.1.1 // indirect
	github.com/cloudwego/base64x v0.1.4 // indirect
	github.com/cloudwego/iasm v0.2.0 // indirect
	github.com/gabriel-vasile/mimetype v1.4.3 // indirect
	github.com/gin-contrib/sse v0.1.0 // indirect
	github.com/go-playground/locales v0.14.1 // indirect
	github.com/go-playground/universal-translator v0.18.1 // indirect
	github.com/go-playground/validator/v10 v10.20.0 // indirect
	github.com/goccy/go-json v0.10.2 // indirect
	github.com/jackc/pgpassfile v1.0.0 // indirect
	github.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761 // indirect
	github.com/jackc/pgx/v5 v5.6.0 // indirect
	github.com/jackc/puddle/v2 v2.2.2 // indirect
	github.com/jinzhu/inflection v1.0.0 // indirect
	github.com/jinzhu/now v1.1.5 // indirect
	github.com/json-iterator/go v1.1.12 // indirect
	github.com/klauspost/cpuid/v2 v2.2.7 // indirect
	github.com/kr/text v0.2.0 // indirect
	github.com/leodido/go-urn v1.4.0 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect
	github.com/modern-go/reflect2 v1.0.2 // indirect
	github.com/pelletier/go-toml/v2 v2.2.2 // indirect
	github.com/richardlehane/msoleps v1.0.3 // indirect
	github.com/rogpeppe/go-internal v1.14.1 // indirect
	github.com/twitchyliquid64/golang-asm v0.15.1 // indirect
	github.com/ugorji/go/codec v1.2.12 // indirect
	golang.org/x/arch v0.8.0 // indirect
	golang.org/x/crypto v0.39.0 // indirect
	golang.org/x/net v0.41.0 // indirect
	golang.org/x/sync v0.15.0 // indirect
	golang.org/x/sys v0.33.0 // indirect
	golang.org/x/text v0.26.0 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20250707201910-8d1bb00bc6a7 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
)

=== go.sum ===
github.com/bytedance/sonic v1.11.6 h1:oUp34TzMlL+OY1OUWxHqsdkgC/Zfc85zGqw9siXjrc0=
github.com/bytedance/sonic v1.11.6/go.mod h1:LysEHSvpvDySVdC2f87zGWf6CIKJcAvqab1ZaiQtds4=
github.com/bytedance/sonic/loader v0.1.1 h1:c+e5Pt1k/cy5wMveRDyk2X4B9hF4g7an8N3zCYjJFNM=
github.com/bytedance/sonic/loader v0.1.1/go.mod h1:ncP89zfokxS5LZrJxl5z0UJcsk4M4yY2JpfqGeCtNLU=
github.com/cloudwego/base64x v0.1.4 h1:jwCgWpFanWmN8xoIUHa2rtzmkd5J2plF/dnLS6Xd/0Y=
github.com/cloudwego/base64x v0.1.4/go.mod h1:0zlkT4Wn5C6NdauXdJRhSKRlJvmclQ1hhJgA0rcu/8w=
github.com/cloudwego/iasm v0.2.0 h1:1KNIy1I1H9hNNFEEH3DVnI4UujN+1zjpuk6gwHLTssg=
github.com/cloudwego/iasm v0.2.0/go.mod h1:8rXZaNYT2n95jn+zTI1sDr+IgcD2GVs0nlbbQPiEFhY=
github.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=
github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/gabriel-vasile/mimetype v1.4.3 h1:in2uUcidCuFcDKtdcBxlR0rJ1+fsokWf+uqxgUFjbI0=
github.com/gabriel-vasile/mimetype v1.4.3/go.mod h1:d8uq/6HKRL6CGdk+aubisF/M5GcPfT7nKyLpA0lbSSk=
github.com/gin-contrib/sse v0.1.0 h1:Y/yl/+YNO8GZSjAhjMsSuLt29uWRFHdHYUb5lYOV9qE=
github.com/gin-contrib/sse v0.1.0/go.mod h1:RHrZQHXnP2xjPF+u1gW/2HnVO7nvIa9PG3Gm+fLHvGI=
github.com/gin-gonic/gin v1.10.1 h1:T0ujvqyCSqRopADpgPgiTT63DUQVSfojyME59Ei63pQ=
github.com/gin-gonic/gin v1.10.1/go.mod h1:4PMNQiOhvDRa013RKVbsiNwoyezlm2rm0uX/T7kzp5Y=
github.com/go-logr/logr v1.4.3 h1:CjnDlHq8ikf6E492q6eKboGOC0T8CDaOvkHCIg8idEI=
github.com/go-logr/logr v1.4.3/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=
github.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=
github.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=
github.com/go-playground/assert/v2 v2.2.0 h1:JvknZsQTYeFEAhQwI4qEt9cyV5ONwRHC+lYKSsYSR8s=
github.com/go-playground/assert/v2 v2.2.0/go.mod h1:VDjEfimB/XKnb+ZQfWdccd7VUvScMdVu0Titje2rxJ4=
github.com/go-playground/locales v0.14.1 h1:EWaQ/wswjilfKLTECiXz7Rh+3BjFhfDFKv/oXslEjJA=
github.com/go-playground/locales v0.14.1/go.mod h1:hxrqLVvrK65+Rwrd5Fc6F2O76J/NuW9t0sjnWqG1slY=
github.com/go-playground/universal-translator v0.18.1 h1:Bcnm0ZwsGyWbCzImXv+pAJnYK9S473LQFuzCbDbfSFY=
github.com/go-playground/universal-translator v0.18.1/go.mod h1:xekY+UJKNuX9WP91TpwSH2VMlDf28Uj24BCp08ZFTUY=
github.com/go-playground/validator/v10 v10.20.0 h1:K9ISHbSaI0lyB2eWMPJo+kOS/FBExVwjEviJTixqxL8=
github.com/go-playground/validator/v10 v10.20.0/go.mod h1:dbuPbCMFw/DrkbEynArYaCwl3amGuJotoKCe95atGMM=
github.com/goccy/go-json v0.10.2 h1:CrxCmQqYDkv1z7lO7Wbh2HN93uovUHgrECaO5ZrCXAU=
github.com/goccy/go-json v0.10.2/go.mod h1:6MelG93GURQebXPDq3khkgXZkazVtN9CRI+MGFi0w8I=
github.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=
github.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=
github.com/google/go-cmp v0.7.0 h1:wk8382ETsv4JYUZwIsn6YpYiWiBsYLSJiTsyBybVuN8=
github.com/google/go-cmp v0.7.0/go.mod h1:pXiqmnSA92OHEEa9HXL2W4E7lf9JzCmGVUdgjX3N/iU=
github.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=
github.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=
github.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
github.com/jackc/pgpassfile v1.0.0 h1:/6Hmqy13Ss2zCq62VdNG8tM1wchn8zjSGOBJ6icpsIM=
github.com/jackc/pgpassfile v1.0.0/go.mod h1:CEx0iS5ambNFdcRtxPj5JhEz+xB6uRky5eyVu/W2HEg=
github.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761 h1:iCEnooe7UlwOQYpKFhBabPMi4aNAfoODPEFNiAnClxo=
github.com/jackc/pgservicefile v0.0.0-20240606120523-5a60cdf6a761/go.mod h1:5TJZWKEWniPve33vlWYSoGYefn3gLQRzjfDlhSJ9ZKM=
github.com/jackc/pgx/v5 v5.6.0 h1:SWJzexBzPL5jb0GEsrPMLIsi/3jOo7RHlzTjcAeDrPY=
github.com/jackc/pgx/v5 v5.6.0/go.mod h1:DNZ/vlrUnhWCoFGxHAG8U2ljioxukquj7utPDgtQdTw=
github.com/jackc/puddle/v2 v2.2.2 h1:PR8nw+E/1w0GLuRFSmiioY6UooMp6KJv0/61nB7icHo=
github.com/jackc/puddle/v2 v2.2.2/go.mod h1:vriiEXHvEE654aYKXXjOvZM39qJ0q+azkZFrfEOc3H4=
github.com/jinzhu/inflection v1.0.0 h1:K317FqzuhWc8YvSVlFMCCUb36O/S9MCKRDI7QkRKD/E=
github.com/jinzhu/inflection v1.0.0/go.mod h1:h+uFLlag+Qp1Va5pdKtLDYj+kHp5pxUVkryuEj+Srlc=
github.com/jinzhu/now v1.1.5 h1:/o9tlHleP7gOFmsnYNz3RGnqzefHA47wQpKrrdTIwXQ=
github.com/jinzhu/now v1.1.5/go.mod h1:d3SSVoowX0Lcu0IBviAWJpolVfI5UJVZZ7cO71lE/z8=
github.com/joho/godotenv v1.5.1 h1:7eLL/+HRGLY0ldzfGMeQkb7vMd0as4CfYvUVzLqw0N0=
github.com/joho/godotenv v1.5.1/go.mod h1:f4LDr5Voq0i2e/R5DDNOoa2zzDfwtkZa6DnEwAbqwq4=
github.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=
github.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=
github.com/klauspost/cpuid/v2 v2.0.9/go.mod h1:FInQzS24/EEf25PyTYn52gqo7WaD8xa0213Md/qVLRg=
github.com/klauspost/cpuid/v2 v2.2.7 h1:ZWSB3igEs+d0qvnxR/ZBzXVmxkgt8DdzP6m9pfuVLDM=
github.com/klauspost/cpuid/v2 v2.2.7/go.mod h1:Lcz8mBdAVJIBVzewtcLocK12l3Y+JytZYpaMropDUws=
github.com/knz/go-libedit v1.10.1/go.mod h1:MZTVkCWyz0oBc7JOWP3wNAzd002ZbM/5hgShxwh4x8M=
github.com/kr/pretty v0.3.0 h1:WgNl7dwNpEZ6jJ9k1snq4pZsg7DOEN8hP9Xw0Tsjwk0=
github.com/kr/pretty v0.3.0/go.mod h1:640gp4NfQd8pI5XOwp5fnNeVWj67G7CFk/SaSQn7NBk=
github.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=
github.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=
github.com/leodido/go-urn v1.4.0 h1:WT9HwE9SGECu3lg4d/dIA+jxlljEa1/ffXKmRjqdmIQ=
github.com/leodido/go-urn v1.4.0/go.mod h1:bvxc+MVxLKB4z00jd1z+Dvzr47oO32F/QSNjSBOlFxI=
github.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=
github.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=
github.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=
github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=
github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=
github.com/modern-go/reflect2 v1.0.2 h1:xBagoLtFs94CBntxluKeaWgTMpvLxC4ur3nMaC9Gz0M=
github.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=
github.com/pelletier/go-toml/v2 v2.2.2 h1:aYUidT7k73Pcl9nb2gScu7NSrKCSHIDE89b3+6Wq+LM=
github.com/pelletier/go-toml/v2 v2.2.2/go.mod h1:1t835xjRzz80PqgE6HHgN2JOsmgYu/h4qDAS4n929Rs=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/richardlehane/msoleps v1.0.3 h1:aznSZzrwYRl3rLKRT3gUk9am7T/mLNSnJINvN0AQoVM=
github.com/richardlehane/msoleps v1.0.3/go.mod h1:BWev5JBpU9Ko2WAgmZEuiz4/u3ZYTKbjLycmwiWUfWg=
github.com/rogpeppe/go-internal v1.14.1 h1:UQB4HGPB6osV0SQTLymcB4TgvyWu6ZyliaW0tI/otEQ=
github.com/rogpeppe/go-internal v1.14.1/go.mod h1:MaRKkUm5W0goXpeCfT7UZI6fk/L7L7so1lCWt35ZSgc=
github.com/sirupsen/logrus v1.9.3 h1:dueUQJ1C2q9oE3F7wvmSGAaVtTmUizReu6fjN8uqzbQ=
github.com/sirupsen/logrus v1.9.3/go.mod h1:naHLuLoDiP4jHNo9R0sCBMtWGeIprob74mVsIT4qYEQ=
github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
github.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=
github.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=
github.com/stretchr/objx v0.5.2/go.mod h1:FRsXN1f5AsAjCGJKqEizvkpNtU+EGNCLh3NxZ/8L+MA=
github.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=
github.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=
github.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=
github.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=
github.com/stretchr/testify v1.8.1/go.mod h1:w2LPCIKwWwSfY2zedu0+kehJoqGctiVI29o6fzry7u4=
github.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=
github.com/stretchr/testify v1.9.0 h1:HtqpIVDClZ4nwg75+f6Lvsy/wHu+3BoSGCbBAcpTsTg=
github.com/stretchr/testify v1.9.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=
github.com/twitchyliquid64/golang-asm v0.15.1 h1:SU5vSMR7hnwNxj24w34ZyCi/FmDZTkS4MhqMhdFk5YI=
github.com/twitchyliquid64/golang-asm v0.15.1/go.mod h1:a1lVb/DtPvCB8fslRZhAngC2+aY1QWCk3Cedj/Gdt08=
github.com/ugorji/go/codec v1.2.12 h1:9LC83zGrHhuUA9l16C9AHXAqEV/2wBQ4nkvumAE65EE=
github.com/ugorji/go/codec v1.2.12/go.mod h1:UNopzCgEMSXjBc6AOMqYvWC1ktqTAfzJZUZgYf6w6lg=
github.com/unidoc/unioffice v1.39.0 h1:Wo5zvrzCqhyK/1Zi5dg8a5F5+NRftIMZPnFPYwruLto=
github.com/unidoc/unioffice v1.39.0/go.mod h1:Axz6ltIZZTUUyHoEnPe4Mb3VmsN4TRHT5iZCGZ1rgnU=
go.opentelemetry.io/auto/sdk v1.1.0 h1:cH53jehLUN6UFLY71z+NDOiNJqDdPRaXzTel0sJySYA=
go.opentelemetry.io/auto/sdk v1.1.0/go.mod h1:3wSPjt5PWp2RhlCcmmOial7AvC4DQqZb7a7wCow3W8A=
go.opentelemetry.io/otel v1.37.0 h1:9zhNfelUvx0KBfu/gb+ZgeAfAgtWrfHJZcAqFC228wQ=
go.opentelemetry.io/otel v1.37.0/go.mod h1:ehE/umFRLnuLa/vSccNq9oS1ErUlkkK71gMcN34UG8I=
go.opentelemetry.io/otel/metric v1.37.0 h1:mvwbQS5m0tbmqML4NqK+e3aDiO02vsf/WgbsdpcPoZE=
go.opentelemetry.io/otel/metric v1.37.0/go.mod h1:04wGrZurHYKOc+RKeye86GwKiTb9FKm1WHtO+4EVr2E=
go.opentelemetry.io/otel/sdk v1.37.0 h1:ItB0QUqnjesGRvNcmAcU0LyvkVyGJ2xftD29bWdDvKI=
go.opentelemetry.io/otel/sdk v1.37.0/go.mod h1:VredYzxUvuo2q3WRcDnKDjbdvmO0sCzOvVAiY+yUkAg=
go.opentelemetry.io/otel/sdk/metric v1.37.0 h1:90lI228XrB9jCMuSdA0673aubgRobVZFhbjxHHspCPc=
go.opentelemetry.io/otel/sdk/metric v1.37.0/go.mod h1:cNen4ZWfiD37l5NhS+Keb5RXVWZWpRE+9WyVCpbo5ps=
go.opentelemetry.io/otel/trace v1.37.0 h1:HLdcFNbRQBE2imdSEgm/kwqmQj1Or1l/7bW6mxVK7z4=
go.opentelemetry.io/otel/trace v1.37.0/go.mod h1:TlgrlQ+PtQO5XFerSPUYG0JSgGyryXewPGyayAWSBS0=
golang.org/x/arch v0.0.0-20210923205945-b76863e36670/go.mod h1:5om86z9Hs0C8fWVUuoMHwpExlXzs5Tkyp9hOrfG7pp8=
golang.org/x/arch v0.8.0 h1:3wRIsP3pM4yUptoR96otTUOXI367OS0+c9eeRi9doIc=
golang.org/x/arch v0.8.0/go.mod h1:FEVrYAQjsQXMVJ1nsMoVVXPZg6p2JE2mx8psSWTDQys=
golang.org/x/crypto v0.39.0 h1:SHs+kF4LP+f+p14esP5jAoDpHU8Gu/v9lFRK6IT5imM=
golang.org/x/crypto v0.39.0/go.mod h1:L+Xg3Wf6HoL4Bn4238Z6ft6KfEpN0tJGo53AAPC632U=
golang.org/x/net v0.41.0 h1:vBTly1HeNPEn3wtREYfy4GZ/NECgw2Cnl+nK6Nz3uvw=
golang.org/x/net v0.41.0/go.mod h1:B/K4NNqkfmg07DQYrbwvSluqCJOOXwUjeb/5lOisjbA=
golang.org/x/sync v0.15.0 h1:KWH3jNZsfyT6xfAfKiz6MRNmd46ByHDYaZ7KSkCtdW8=
golang.org/x/sync v0.15.0/go.mod h1:1dzgHSNfp02xaA81J2MS99Qcpr2w7fw1gpm99rleRqA=
golang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.33.0 h1:q3i8TbbEz+JRD9ywIRlyRAQbM0qF7hu24q3teo2hbuw=
golang.org/x/sys v0.33.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=
golang.org/x/text v0.26.0 h1:P42AVeLghgTYr4+xUnTRKDMqpar+PtX7KWuNQL21L8M=
golang.org/x/text v0.26.0/go.mod h1:QK15LZJUUQVJxhz7wXgxSy/CJaTFjd0G+YLonydOVQA=
gonum.org/v1/gonum v0.16.0 h1:5+ul4Swaf3ESvrOnidPp4GZbzf0mxVQpDCYUQE7OJfk=
gonum.org/v1/gonum v0.16.0/go.mod h1:fef3am4MQ93R2HHpKnLk4/Tbh/s0+wqD5nfa6Pnwy4E=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250707201910-8d1bb00bc6a7 h1:pFyd6EwwL2TqFf8emdthzeX+gZE1ElRq3iM8pui4KBY=
google.golang.org/genproto/googleapis/rpc v0.0.0-20250707201910-8d1bb00bc6a7/go.mod h1:qQ0YXyHHx3XkvlzUtpXDkS29lDSafHMZBAZDc03LQ3A=
google.golang.org/grpc v1.75.0 h1:+TW+dqTd2Biwe6KKfhE5JpiYIBWq865PhKGSXiivqt4=
google.golang.org/grpc v1.75.0/go.mod h1:JtPAzKiq4v1xcAB2hydNlWI2RnF85XXcV0mhKXr2ecQ=
google.golang.org/protobuf v1.36.6 h1:z1NpPI8ku2WgiWnf+t9wTPsn6eP1L7ksHUlkfLvd9xY=
google.golang.org/protobuf v1.36.6/go.mod h1:jduwjTPXsFjZGTmRluh+L6NjiWu7pchiJ2/5YcXBHnY=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=
gopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=
gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
gorm.io/driver/postgres v1.6.0 h1:2dxzU8xJ+ivvqTRph34QX+WrRaJlmfyPqXmoGVjMBa4=
gorm.io/driver/postgres v1.6.0/go.mod h1:vUw0mrGgrTK+uPHEhAdV4sfFELrByKVGnaVRkXDhtWo=
gorm.io/gorm v1.30.2 h1:f7bevlVoVe4Byu3pmbWPVHnPsLoWaMjEb7/clyr9Ivs=
gorm.io/gorm v1.30.2/go.mod h1:8Z33v652h4//uMA76KjeDH8mJXPm1QNCYrMeatR0DOE=
nullprogram.com/x/optparse v1.0.0/go.mod h1:KdyPE+Igbe0jQUrVfMqDMeJQIJZEuyV7pjYmp6pbG50=
rsc.io/pdf v0.1.1/go.mod h1:n8OzWcQ6Sp37PL01nO98y4iUCRdTGarVfzxY20ICaU4=

=== internal/config/config.go ===
package config

import (
	"os"

	"github.com/joho/godotenv"
)

type Config struct {
	DBURL        string
	GRPCPort     string
	HTTPPort     string
	RedisAddr    string
	KafkaBrokers string
}

func Load() (*Config, error) {
	if err := godotenv.Load(); err != nil {
		return nil, err
	}

	return &Config{
		DBURL:        os.Getenv("DB_URL"),        // e.g., postgres://user:pass@db:5432/hrdb
		GRPCPort:     os.Getenv("GRPC_PORT"),     // e.g., :50051
		HTTPPort:     os.Getenv("HTTP_PORT"),     // e.g., :8080
		RedisAddr:    os.Getenv("REDIS_ADDR"),    // e.g., redis:6379
		KafkaBrokers: os.Getenv("KAFKA_BROKERS"), // e.g., kafka:9092
	}, nil
}

=== internal/db/db.go ===
package db

import (
	"gorm.io/driver/postgres"
	"gorm.io/gorm"
)

func Connect(dbURL string) (*gorm.DB, error) {
	return gorm.Open(postgres.Open(dbURL), &gorm.Config{})
}

=== internal/handlers/handlers.go ===
package handlers

import (
	"os"

	"github.com/gin-gonic/gin"
	"gorm.io/gorm"
)

// SetupRoutes настраивает маршруты для API Gateway
func SetupRoutes(r *gin.Engine, db *gorm.DB) {
	api := r.Group("/api")
	{
		api.POST("/upload/resume", func(c *gin.Context) { UploadResume(c, db) })
		api.POST("/upload/vacancy", func(c *gin.Context) { UploadVacancy(c, db) })
		api.POST("/analyze", func(c *gin.Context) { AnalyzeResume(c, db) })
		api.GET("/health", HealthCheck)
	}

	r.GET("/interview", func(c *gin.Context) {
		// Логируем попытку доступа к файлу
		log.Printf("Serving interview page")

		// Проверяем существование файла
		if _, err := os.Stat("/app/frontend/interview.html"); os.IsNotExist(err) {
			log.Printf("File does not exist: %v", err)
			c.JSON(404, gin.H{"error": "File not found"})
			return
		}

		c.File("/app/frontend/interview.html")
	})

	r.GET("/health", HealthCheck)
}

// SetupResumeRoutes настраивает маршруты для Resume Service
func SetupResumeRoutes(r *gin.Engine, db *gorm.DB) {
	r.POST("/upload/resume", func(c *gin.Context) { UploadResume(c, db) })
	r.POST("/upload/vacancy", func(c *gin.Context) { UploadVacancy(c, db) })
	r.POST("/analyze", func(c *gin.Context) { AnalyzeResume(c, db) })
	r.GET("/health", HealthCheck)
}

// HealthCheck проверяет статус сервиса
func HealthCheck(c *gin.Context) {
	c.JSON(200, gin.H{"status": "ok"})
}

=== internal/handlers/resume.go ===
package handlers

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/unidoc/unioffice/common/license"
	"google.golang.org/grpc/credentials/insecure"
	"net/http"
	"os"
	"path/filepath"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
	"github.com/moverq1337/VTBHack/internal/models"
	"github.com/moverq1337/VTBHack/internal/pb"
	"github.com/moverq1337/VTBHack/internal/utils"
	"github.com/sirupsen/logrus"
	"github.com/unidoc/unioffice/document"
	"google.golang.org/grpc"
	"gorm.io/gorm"
)

var log = logrus.New()

// UploadResume обрабатывает загрузку резюме в формате DOCX
func UploadResume(c *gin.Context, db *gorm.DB) {
	log.Info("Начало загрузки резюме DOCX")

	file, err := c.FormFile("resume")
	if err != nil {
		log.WithError(err).Error("Ошибка загрузки файла")
		c.JSON(http.StatusBadRequest, gin.H{"error": "Файл не загружен: " + err.Error()})
		return
	}

	ext := filepath.Ext(file.Filename)
	if ext != ".docx" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Поддерживается только DOCX формат"})
		return
	}

	candidateID := uuid.New()
	filePath := filepath.Join("uploads", candidateID.String()+ext)
	if err := os.MkdirAll("uploads", 0755); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка создания директории"})
		return
	}
	if err := c.SaveUploadedFile(file, filePath); err != nil {
		log.WithError(err).Error("Ошибка сохранения файла")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения файла"})
		return
	}
	defer os.Remove(filePath) // Удаляем временный файл после обработки

	// Извлекаем текст из DOCX
	text, err := extractTextFromDOCX(filePath)
	if err != nil {
		log.WithError(err).Error("Ошибка извлечения текста из DOCX")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка извлечения текста из DOCX: " + err.Error()})
		return
	}

	// Загружаем на Яндекс.Диск
	diskURL, err := utils.UploadToYandexDisk(filePath, file.Filename)
	if err != nil {
		log.WithError(err).Error("Ошибка загрузки на Яндекс.Диск")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка загрузки на Яндекс.Диск: " + err.Error()})
		return
	}

	resume := models.Resume{
		ID:          uuid.New(),
		CandidateID: candidateID,
		Text:        text,
		ParsedData:  "{}",
		FileURL:     diskURL,
	}

	// Вызов парсинга резюме
	grpchost := "scoring-service:50051"
	conn, err := grpc.NewClient(grpchost, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.WithError(err).Error("Ошибка gRPC-соединения для парсинга")
	} else {
		defer conn.Close()

		client := pb.NewNLPServiceClient(conn)
		parseResp, err := client.ParseResume(context.Background(), &pb.ParseRequest{
			Text: text,
		})

		if err != nil {
			log.WithError(err).Error("Ошибка парсинга резюме")
		} else {
			// Сохраняем результаты парсинга
			resume.ParsedData = parseResp.ParsedData
		}
	}

	if err := db.Create(&resume).Error; err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения в БД"})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"candidate_id": candidateID.String(),
		"file_url":     diskURL,
		"resume_id":    resume.ID.String(),
		"text_preview": truncateText(text, 200), // Первые 200 символов для предпросмотра
	})
}

// extractTextFromDOCX извлекает текст из DOCX файла
func extractTextFromDOCX(filePath string) (string, error) {
	apiKey := os.Getenv("UNIDOC_LICENSE_API_KEY")
	if apiKey == "" {
		log.Fatal("UNIDOC_LICENSE_API_KEY environment variable not set")
	}

	// Установка API ключа для UniDoc
	err := license.SetMeteredKey(apiKey)
	if err != nil {
		log.Fatalf("Ошибка инициализации UniDoc license: %v", err)
	}
	doc, err := document.Open(filePath)
	if err != nil {
		return "", fmt.Errorf("ошибка открытия DOCX файла: %v", err)
	}

	var text string
	for _, para := range doc.Paragraphs() {
		for _, run := range para.Runs() {
			text += run.Text()
		}
		text += "\n"
	}

	// Также извлекаем текст из таблиц
	for _, tbl := range doc.Tables() {
		for _, row := range tbl.Rows() {
			for _, cell := range row.Cells() {
				for _, para := range cell.Paragraphs() {
					for _, run := range para.Runs() {
						text += run.Text() + " "
					}
				}
			}
			text += "\n"
		}
	}

	return text, nil
}

// truncateText обрезает текст до указанной длины
func truncateText(text string, maxLength int) string {
	if len(text) <= maxLength {
		return text
	}
	return text[:maxLength] + "..."
}

// UploadVacancy обрабатывает загрузку вакансии
func UploadVacancy(c *gin.Context, db *gorm.DB) {
	type VacancyRequest struct {
		Title            string `json:"title"`
		Requirements     string `json:"requirements"`
		Responsibilities string `json:"responsibilities"`
		Region           string `json:"region"`
		City             string `json:"city"`
		EmploymentType   string `json:"employment_type"`
		WorkSchedule     string `json:"work_schedule"`
		Experience       string `json:"experience"`
		Education        string `json:"education"`
		SalaryMin        int    `json:"salary_min"`
		SalaryMax        int    `json:"salary_max"`
		Languages        string `json:"languages"`
		Skills           string `json:"skills"`
	}

	var req VacancyRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Неверный формат данных"})
		return
	}

	vacancy := models.Vacancy{
		ID:               uuid.New(),
		Title:            req.Title,
		Requirements:     req.Requirements,
		Responsibilities: req.Responsibilities,
		Region:           req.Region,
		City:             req.City,
		EmploymentType:   req.EmploymentType,
		WorkSchedule:     req.WorkSchedule,
		Experience:       req.Experience,
		Education:        req.Education,
		SalaryMin:        req.SalaryMin,
		SalaryMax:        req.SalaryMax,
		Languages:        req.Languages,
		Skills:           req.Skills,
	}
	if err := db.Create(&vacancy).Error; err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения в БД"})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"vacancy_id": vacancy.ID.String(),
		"title":      vacancy.Title,
	})
}

// AnalyzeResume обрабатывает анализ резюме
func AnalyzeResume(c *gin.Context, db *gorm.DB) {
	type AnalyzeRequest struct {
		ResumeID  uuid.UUID `json:"resume_id"`
		VacancyID uuid.UUID `json:"vacancy_id"`
	}

	var req AnalyzeRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Неверный формат запроса"})
		return
	}

	var resume models.Resume
	if err := db.First(&resume, "id = ?", req.ResumeID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Резюме не найдено"})
		return
	}

	var vacancy models.Vacancy
	if err := db.First(&vacancy, "id = ?", req.VacancyID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Вакансия не найдена"})
		return
	}

	grpchost := "scoring-service:50051"

	conn, err := grpc.NewClient(grpchost, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		log.WithError(err).Error("Ошибка gRPC-соединения")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка подключения к сервису анализа"})
		return
	}
	defer conn.Close()

	client := pb.NewNLPServiceClient(conn)

	// Сопоставление с вакансией
	matchResp, err := client.MatchResumeVacancy(context.Background(), &pb.MatchRequest{
		ResumeText:  resume.Text,
		VacancyText: fmt.Sprintf("%s %s %s %s", vacancy.Title, vacancy.Requirements, vacancy.Responsibilities, vacancy.Skills),
	})
	if err != nil {
		log.WithError(err).Error("Ошибка сопоставления")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сопоставления с вакансией"})
		return
	}

	// Парсим резюме для получения деталей
	parseResp, err := client.ParseResume(context.Background(), &pb.ParseRequest{
		Text: resume.Text,
	})
	if err != nil {
		log.WithError(err).Error("Ошибка парсинга резюме")
	}

	var parsedData map[string]interface{}
	if err := json.Unmarshal([]byte(parseResp.ParsedData), &parsedData); err != nil {
		log.WithError(err).Error("Ошибка разбора JSON данных парсинга")
		parsedData = make(map[string]interface{})
	}

	// Сохраняем результаты анализа
	analysisResult := models.AnalysisResult{
		ID:         uuid.New(),
		ResumeID:   resume.ID,
		VacancyID:  vacancy.ID,
		MatchScore: float64(matchResp.Score),
		Details:    parseResp.ParsedData, // Сохраняем полные данные парсинга
		CreatedAt:  time.Now(),
	}

	if err := db.Create(&analysisResult).Error; err != nil {
		log.WithError(err).Error("Ошибка сохранения результатов анализа")
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения результатов"})
		return
	}

	// Сохраняем детали анализа
	if skills, ok := parsedData["skills"].(map[string]interface{}); ok {
		for category, skillList := range skills {
			if skillsArr, ok := skillList.([]interface{}); ok {
				for _, skill := range skillsArr {
					analysisDetail := models.AnalysisDetail{
						ID:               uuid.New(),
						AnalysisResultID: analysisResult.ID,
						Category:         "skills",
						Criteria:         category,
						ResumeValue:      fmt.Sprintf("%v", skill),
						VacancyValue:     "",  // Можно добавить проверку наличия в вакансии
						MatchScore:       0.8, // Заглушка
						Weight:           0.3, // Заглушка
						CreatedAt:        time.Now(),
					}
					if err := db.Create(&analysisDetail).Error; err != nil {
						log.WithError(err).Error("Ошибка сохранения деталей анализа")
					}
				}
			}
		}
	}

	// Формируем ответ
	c.JSON(http.StatusOK, gin.H{
		"analysis_id":  analysisResult.ID.String(),
		"resume_id":    resume.ID.String(),
		"vacancy_id":   vacancy.ID.String(),
		"match_score":  fmt.Sprintf("%.2f%%", matchResp.Score*100),
		"candidate_id": resume.CandidateID.String(),
		"created_at":   analysisResult.CreatedAt,
		"details":      parsedData, // Добавляем детали в ответ
	})
}

=== internal/models/models.go ===
package models

import (
	"github.com/google/uuid"
	"time"
)

type Vacancy struct {
	ID               uuid.UUID `gorm:"primaryKey;autoIncrement" json:"-"`
	Title            string    `gorm:"type:varchar(255)"`
	Requirements     string    `gorm:"type:text"`
	Responsibilities string    `gorm:"type:text"`
	Region           string    `gorm:"type:varchar(100)"`
	City             string    `gorm:"type:varchar(100)"`
	EmploymentType   string    `gorm:"type:varchar(50)"`  // Полная, частичная, удаленная
	WorkSchedule     string    `gorm:"type:varchar(50)"`  // Полный день, сменный и т.д.
	Experience       string    `gorm:"type:varchar(50)"`  // Требуемый опыт
	Education        string    `gorm:"type:varchar(100)"` // Требуемое образование
	SalaryMin        int       `gorm:"type:integer"`
	SalaryMax        int       `gorm:"type:integer"`
	Languages        string    `gorm:"type:text"` // Требуемые языки
	Skills           string    `gorm:"type:text"` // Ключевые навыки
	CreatedAt        time.Time
}

type Resume struct {
	ID           uuid.UUID `gorm:"primaryKey;autoIncrement" json:"-"`
	CandidateID  uuid.UUID `gorm:"type:uuid"`
	Text         string    `gorm:"type:text"`
	ParsedData   string    `gorm:"type:jsonb"`
	FileURL      string    `gorm:"type:text"`
	Experience   int       `gorm:"type:integer"` // Опыт в годах
	Education    string    `gorm:"type:varchar(100)"`
	Skills       string    `gorm:"type:text"`
	Languages    string    `gorm:"type:text"`
	SalaryExpect int       `gorm:"type:integer"`
	CreatedAt    time.Time
}

type AnalysisResult struct {
	ID         uuid.UUID `gorm:"primaryKey;type:uuid" json:"-"`
	ResumeID   uuid.UUID `gorm:"type:uuid"`
	VacancyID  uuid.UUID `gorm:"type:uuid"`
	MatchScore float64   `gorm:"type:decimal(5,2)"`
	Details    string    `gorm:"type:jsonb;default:'{}'"`
	CreatedAt  time.Time
}

type AnalysisDetail struct {
	ID               uuid.UUID `gorm:"primaryKey;type:uuid" json:"-"`
	AnalysisResultID uuid.UUID `gorm:"type:uuid"`
	Category         string    `gorm:"type:varchar(100)"` // Например: "skills", "experience", "education"
	Criteria         string    `gorm:"type:text"`         // Конкретный критерий
	ResumeValue      string    `gorm:"type:text"`         // Значение из резюме
	VacancyValue     string    `gorm:"type:text"`         // Требование из вакансии
	MatchScore       float64   `gorm:"type:decimal(3,2)"` // Оценка соответствия (0-1)
	Weight           float64   `gorm:"type:decimal(3,2)"` // Вес критерия в общей оценке
	CreatedAt        time.Time
}

=== internal/pb/nlp.pb.go ===
// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.8
// 	protoc        v6.32.0
// source: proto/nlp.proto

package pb

import (
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"

	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type ParseRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Text          string                 `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ParseRequest) Reset() {
	*x = ParseRequest{}
	mi := &file_proto_nlp_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ParseRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ParseRequest) ProtoMessage() {}

func (x *ParseRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_nlp_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ParseRequest.ProtoReflect.Descriptor instead.
func (*ParseRequest) Descriptor() ([]byte, []int) {
	return file_proto_nlp_proto_rawDescGZIP(), []int{0}
}

func (x *ParseRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

type ParseResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ParsedData    string                 `protobuf:"bytes,1,opt,name=parsed_data,json=parsedData,proto3" json:"parsed_data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ParseResponse) Reset() {
	*x = ParseResponse{}
	mi := &file_proto_nlp_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ParseResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ParseResponse) ProtoMessage() {}

func (x *ParseResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_nlp_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ParseResponse.ProtoReflect.Descriptor instead.
func (*ParseResponse) Descriptor() ([]byte, []int) {
	return file_proto_nlp_proto_rawDescGZIP(), []int{1}
}

func (x *ParseResponse) GetParsedData() string {
	if x != nil {
		return x.ParsedData
	}
	return ""
}

type MatchRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ResumeText    string                 `protobuf:"bytes,1,opt,name=resume_text,json=resumeText,proto3" json:"resume_text,omitempty"`
	VacancyText   string                 `protobuf:"bytes,2,opt,name=vacancy_text,json=vacancyText,proto3" json:"vacancy_text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MatchRequest) Reset() {
	*x = MatchRequest{}
	mi := &file_proto_nlp_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MatchRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MatchRequest) ProtoMessage() {}

func (x *MatchRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_nlp_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MatchRequest.ProtoReflect.Descriptor instead.
func (*MatchRequest) Descriptor() ([]byte, []int) {
	return file_proto_nlp_proto_rawDescGZIP(), []int{2}
}

func (x *MatchRequest) GetResumeText() string {
	if x != nil {
		return x.ResumeText
	}
	return ""
}

func (x *MatchRequest) GetVacancyText() string {
	if x != nil {
		return x.VacancyText
	}
	return ""
}

type MatchResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Score         float32                `protobuf:"fixed32,1,opt,name=score,proto3" json:"score,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *MatchResponse) Reset() {
	*x = MatchResponse{}
	mi := &file_proto_nlp_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MatchResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MatchResponse) ProtoMessage() {}

func (x *MatchResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_nlp_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MatchResponse.ProtoReflect.Descriptor instead.
func (*MatchResponse) Descriptor() ([]byte, []int) {
	return file_proto_nlp_proto_rawDescGZIP(), []int{3}
}

func (x *MatchResponse) GetScore() float32 {
	if x != nil {
		return x.Score
	}
	return 0
}

var File_proto_nlp_proto protoreflect.FileDescriptor

const file_proto_nlp_proto_rawDesc = "" +
	"\n" +
	"\x0fproto/nlp.proto\x12\x02pb\"\"\n" +
	"\fParseRequest\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\"0\n" +
	"\rParseResponse\x12\x1f\n" +
	"\vparsed_data\x18\x01 \x01(\tR\n" +
	"parsedData\"R\n" +
	"\fMatchRequest\x12\x1f\n" +
	"\vresume_text\x18\x01 \x01(\tR\n" +
	"resumeText\x12!\n" +
	"\fvacancy_text\x18\x02 \x01(\tR\vvacancyText\"%\n" +
	"\rMatchResponse\x12\x14\n" +
	"\x05score\x18\x01 \x01(\x02R\x05score2\x7f\n" +
	"\n" +
	"NLPService\x124\n" +
	"\vParseResume\x12\x10.pb.ParseRequest\x1a\x11.pb.ParseResponse\"\x00\x12;\n" +
	"\x12MatchResumeVacancy\x12\x10.pb.MatchRequest\x1a\x11.pb.MatchResponse\"\x00B+Z)github.com/moverq1337/VTBHack/internal/pbb\x06proto3"

var (
	file_proto_nlp_proto_rawDescOnce sync.Once
	file_proto_nlp_proto_rawDescData []byte
)

func file_proto_nlp_proto_rawDescGZIP() []byte {
	file_proto_nlp_proto_rawDescOnce.Do(func() {
		file_proto_nlp_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_proto_nlp_proto_rawDesc), len(file_proto_nlp_proto_rawDesc)))
	})
	return file_proto_nlp_proto_rawDescData
}

var file_proto_nlp_proto_msgTypes = make([]protoimpl.MessageInfo, 4)
var file_proto_nlp_proto_goTypes = []any{
	(*ParseRequest)(nil),  // 0: pb.ParseRequest
	(*ParseResponse)(nil), // 1: pb.ParseResponse
	(*MatchRequest)(nil),  // 2: pb.MatchRequest
	(*MatchResponse)(nil), // 3: pb.MatchResponse
}
var file_proto_nlp_proto_depIdxs = []int32{
	0, // 0: pb.NLPService.ParseResume:input_type -> pb.ParseRequest
	2, // 1: pb.NLPService.MatchResumeVacancy:input_type -> pb.MatchRequest
	1, // 2: pb.NLPService.ParseResume:output_type -> pb.ParseResponse
	3, // 3: pb.NLPService.MatchResumeVacancy:output_type -> pb.MatchResponse
	2, // [2:4] is the sub-list for method output_type
	0, // [0:2] is the sub-list for method input_type
	0, // [0:0] is the sub-list for extension type_name
	0, // [0:0] is the sub-list for extension extendee
	0, // [0:0] is the sub-list for field type_name
}

func init() { file_proto_nlp_proto_init() }
func file_proto_nlp_proto_init() {
	if File_proto_nlp_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_proto_nlp_proto_rawDesc), len(file_proto_nlp_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   4,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_proto_nlp_proto_goTypes,
		DependencyIndexes: file_proto_nlp_proto_depIdxs,
		MessageInfos:      file_proto_nlp_proto_msgTypes,
	}.Build()
	File_proto_nlp_proto = out.File
	file_proto_nlp_proto_goTypes = nil
	file_proto_nlp_proto_depIdxs = nil
}

=== internal/pb/nlp_grpc.pb.go ===
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.5.1
// - protoc             v6.32.0
// source: proto/nlp.proto

package pb

import (
	context "context"

	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	NLPService_ParseResume_FullMethodName        = "/pb.NLPService/ParseResume"
	NLPService_MatchResumeVacancy_FullMethodName = "/pb.NLPService/MatchResumeVacancy"
)

// NLPServiceClient is the client API for NLPService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type NLPServiceClient interface {
	ParseResume(ctx context.Context, in *ParseRequest, opts ...grpc.CallOption) (*ParseResponse, error)
	MatchResumeVacancy(ctx context.Context, in *MatchRequest, opts ...grpc.CallOption) (*MatchResponse, error)
}

type nLPServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewNLPServiceClient(cc grpc.ClientConnInterface) NLPServiceClient {
	return &nLPServiceClient{cc}
}

func (c *nLPServiceClient) ParseResume(ctx context.Context, in *ParseRequest, opts ...grpc.CallOption) (*ParseResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ParseResponse)
	err := c.cc.Invoke(ctx, NLPService_ParseResume_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *nLPServiceClient) MatchResumeVacancy(ctx context.Context, in *MatchRequest, opts ...grpc.CallOption) (*MatchResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(MatchResponse)
	err := c.cc.Invoke(ctx, NLPService_MatchResumeVacancy_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// NLPServiceServer is the server API for NLPService service.
// All implementations must embed UnimplementedNLPServiceServer
// for forward compatibility.
type NLPServiceServer interface {
	ParseResume(context.Context, *ParseRequest) (*ParseResponse, error)
	MatchResumeVacancy(context.Context, *MatchRequest) (*MatchResponse, error)
	mustEmbedUnimplementedNLPServiceServer()
}

// UnimplementedNLPServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedNLPServiceServer struct{}

func (UnimplementedNLPServiceServer) ParseResume(context.Context, *ParseRequest) (*ParseResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ParseResume not implemented")
}
func (UnimplementedNLPServiceServer) MatchResumeVacancy(context.Context, *MatchRequest) (*MatchResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method MatchResumeVacancy not implemented")
}
func (UnimplementedNLPServiceServer) mustEmbedUnimplementedNLPServiceServer() {}
func (UnimplementedNLPServiceServer) testEmbeddedByValue()                    {}

// UnsafeNLPServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to NLPServiceServer will
// result in compilation errors.
type UnsafeNLPServiceServer interface {
	mustEmbedUnimplementedNLPServiceServer()
}

func RegisterNLPServiceServer(s grpc.ServiceRegistrar, srv NLPServiceServer) {
	// If the following call pancis, it indicates UnimplementedNLPServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&NLPService_ServiceDesc, srv)
}

func _NLPService_ParseResume_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ParseRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NLPServiceServer).ParseResume(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: NLPService_ParseResume_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NLPServiceServer).ParseResume(ctx, req.(*ParseRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _NLPService_MatchResumeVacancy_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(MatchRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NLPServiceServer).MatchResumeVacancy(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: NLPService_MatchResumeVacancy_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NLPServiceServer).MatchResumeVacancy(ctx, req.(*MatchRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// NLPService_ServiceDesc is the grpc.ServiceDesc for NLPService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var NLPService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "pb.NLPService",
	HandlerType: (*NLPServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "ParseResume",
			Handler:    _NLPService_ParseResume_Handler,
		},
		{
			MethodName: "MatchResumeVacancy",
			Handler:    _NLPService_MatchResumeVacancy_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "proto/nlp.proto",
}

=== internal/utils/grpc_client.go ===
package utils

import (
	"context"
	"github.com/moverq1337/VTBHack/internal/pb"
	"google.golang.org/grpc"
	"os"
)

// CallNLPParse вызывает NLP-сервис для парсинга текста
func CallNLPParse(text string) (string, error) {
	grpcHost := os.Getenv("GRPC_HOST")
	grpcPort := os.Getenv("GRPC_PORT")

	conn, err := grpc.Dial(grpcHost+":"+grpcPort, grpc.WithInsecure())
	if err != nil {
		return "", err
	}
	defer conn.Close()

	client := pb.NewNLPServiceClient(conn)
	resp, err := client.ParseResume(context.Background(), &pb.ParseRequest{Text: text})
	if err != nil {
		return "", err
	}

	return resp.ParsedData, nil
}

=== internal/utils/yandexdisk.go ===
package utils

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"time"
)

// UploadToYandexDisk загружает файл на Яндекс.Диск и возвращает публичную ссылку
func UploadToYandexDisk(filePath, fileName string) (string, error) {
	oauthToken := os.Getenv("YANDEX_DISK_TOKEN")
	if oauthToken == "" {
		return "", fmt.Errorf("YANDEX_DISK_TOKEN environment variable not set")
	}

	client := &http.Client{Timeout: 30 * time.Second}

	// 1. Сначала получаем URL для загрузки
	getUploadURL := fmt.Sprintf("https://cloud-api.yandex.net/v1/disk/resources/upload?path=app:/hr-ai/%s&overwrite=true", fileName)

	req, err := http.NewRequest("GET", getUploadURL, nil)
	if err != nil {
		return "", fmt.Errorf("failed to create request: %v", err)
	}
	req.Header.Set("Authorization", "OAuth "+oauthToken)
	req.Header.Set("Content-Type", "application/json")

	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to get upload URL: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("failed to get upload URL, status: %s, response: %s", resp.Status, string(body))
	}

	// Парсим ответ чтобы получить URL для загрузки
	var uploadResponse struct {
		Href string `json:"href"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&uploadResponse); err != nil {
		return "", fmt.Errorf("failed to parse upload URL response: %v", err)
	}

	// 2. Теперь загружаем файл на полученный URL
	fileData, err := os.ReadFile(filePath)
	if err != nil {
		return "", fmt.Errorf("failed to read file: %v", err)
	}

	uploadReq, err := http.NewRequest("PUT", uploadResponse.Href, bytes.NewReader(fileData))
	if err != nil {
		return "", fmt.Errorf("failed to create upload request: %v", err)
	}
	uploadReq.Header.Set("Content-Type", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")

	uploadResp, err := client.Do(uploadReq)
	if err != nil {
		return "", fmt.Errorf("failed to upload file: %v", err)
	}
	defer uploadResp.Body.Close()

	if uploadResp.StatusCode != http.StatusCreated && uploadResp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(uploadResp.Body)
		return "", fmt.Errorf("upload failed, status: %s, response: %s", uploadResp.Status, string(body))
	}

	// 3. Публикуем файл
	publishURL := fmt.Sprintf("https://cloud-api.yandex.net/v1/disk/resources/publish?path=app:/hr-ai/%s", fileName)
	publishReq, err := http.NewRequest("PUT", publishURL, nil)
	if err != nil {
		return "", fmt.Errorf("failed to create publish request: %v", err)
	}
	publishReq.Header.Set("Authorization", "OAuth "+oauthToken)

	publishResp, err := client.Do(publishReq)
	if err != nil {
		return "", fmt.Errorf("failed to publish file: %v", err)
	}
	defer publishResp.Body.Close()

	if publishResp.StatusCode != http.StatusOK && publishResp.StatusCode != http.StatusAccepted {
		body, _ := io.ReadAll(publishResp.Body)
		return "", fmt.Errorf("publish failed, status: %s, response: %s", publishResp.Status, string(body))
	}

	// 4. Получаем публичную ссылку
	publicURL := fmt.Sprintf("https://cloud-api.yandex.net/v1/disk/resources?path=app:/hr-ai/%s&fields=public_url", fileName)
	publicReq, err := http.NewRequest("GET", publicURL, nil)
	if err != nil {
		return "", fmt.Errorf("failed to create public URL request: %v", err)
	}
	publicReq.Header.Set("Authorization", "OAuth "+oauthToken)

	publicResp, err := client.Do(publicReq)
	if err != nil {
		return "", fmt.Errorf("failed to get public URL: %v", err)
	}
	defer publicResp.Body.Close()

	if publicResp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(publicResp.Body)
		return "", fmt.Errorf("failed to get public URL, status: %s, response: %s", publicResp.Status, string(body))
	}

	var publicResponse struct {
		PublicURL string `json:"public_url"`
	}
	if err := json.NewDecoder(publicResp.Body).Decode(&publicResponse); err != nil {
		return "", fmt.Errorf("failed to parse public URL response: %v", err)
	}

	return publicResponse.PublicURL, nil
}

=== main.go ===
package main

import "fmt"

func main() {
	fmt.Println("git init")
}

=== proto/nlp.proto ===
syntax = "proto3";

package pb;

option go_package = "github.com/moverq1337/VTBHack/internal/pb";

service NLPService {
  rpc ParseResume(ParseRequest) returns (ParseResponse) {}
  rpc MatchResumeVacancy(MatchRequest) returns (MatchResponse) {}
}

message ParseRequest {
  string text = 1;
}

message ParseResponse {
  string parsed_data = 1;
}

message MatchRequest {
  string resume_text = 1;
  string vacancy_text = 2;
}

message MatchResponse {
  float score = 1;
}
=== scripts/migrate.go ===
package scripts

import (
	"log"

	"github.com/moverq1337/VTBHack/internal/config"
	"github.com/moverq1337/VTBHack/internal/db"
	"github.com/moverq1337/VTBHack/internal/models"
)

func Migrate() {
	cfg, err := config.Load()
	if err != nil {
		log.Fatal(err)
	}

	dbConn, err := db.Connect(cfg.DBURL)
	if err != nil {
		log.Fatal(err)
	}

	// Автомиграция всех моделей
	err = dbConn.AutoMigrate(
		&models.Vacancy{},
		&models.Resume{},
		&models.AnalysisResult{},
		&models.AnalysisDetail{}, // ← ДОБАВЬТЕ ЭТУ СТРОКУ
	)
	if err != nil {
		log.Fatal(err)
	}

	log.Println("Миграции завершены")
}

=== wait-for.sh ===
#!/bin/sh
# wait-for.sh

set -e

host="$1"
port="$2"
shift 2
cmd="$@"

until nc -z "$host" "$port"; do
  >&2 echo "Waiting for $host:$port..."
  sleep 2
done

>&2 echo "$host:$port is available - executing command"
exec $cmd
